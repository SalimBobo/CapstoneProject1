{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyt97cS3zXXlaDr+8IrYad",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SalimBobo/CapstoneProject1/blob/main/SalimBoBo_AviaTicket_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo7i21PyFSrc",
        "outputId": "1049e785-0ced-49b2-deda-135ef0664d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/train_data.csv\n",
            "/content/test_data.csv\n",
            "/content/.config/default_configs.db\n",
            "/content/.config/active_config\n",
            "/content/.config/.last_survey_prompt.yaml\n",
            "/content/.config/config_sentinel\n",
            "/content/.config/.last_update_check.json\n",
            "/content/.config/gce\n",
            "/content/.config/.last_opt_in_prompt.yaml\n",
            "/content/.config/logs/2024.04.25/13.24.39.060363.log\n",
            "/content/.config/logs/2024.04.25/13.24.09.661148.log\n",
            "/content/.config/logs/2024.04.25/13.25.23.751786.log\n",
            "/content/.config/logs/2024.04.25/13.25.24.520119.log\n",
            "/content/.config/logs/2024.04.25/13.24.52.912147.log\n",
            "/content/.config/logs/2024.04.25/13.25.09.448224.log\n",
            "/content/.config/configurations/config_default\n"
          ]
        }
      ],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Ma'lumotlarni oldindan qayta ishlash funksiyasi\n",
        "def preprocess_data(df):\n",
        "    city_dic = {'Mumbai':1, 'Delhi':2, 'Bangalore':3, 'Kolkata':4, 'Hyderabad':5, 'Chennai':6}\n",
        "    df['sorce_new_cities'] = [city_dic[i] for i in df['source_city']]\n",
        "    df['destination_new_cities'] = [city_dic[i] for i in df['destination_city']]\n",
        "    df.drop('flight', axis=1, inplace=True)\n",
        "    df_adder = pd.get_dummies(df[['class', 'stops', 'airline', 'arrival_time', 'departure_time']], dtype='int')\n",
        "    df = pd.concat([df, df_adder], axis=1)\n",
        "    df.drop(columns=['airline', 'source_city', 'departure_time', 'stops', 'arrival_time',\n",
        "       'destination_city', 'class'], inplace=True)\n",
        "    return df\n",
        "\n",
        "# Ma'lumotlarni yuklash\n",
        "df_train = pd.read_csv(\"/content/train_data.csv\")\n",
        "df_test = pd.read_csv(\"/content/test_data.csv\")\n",
        "\n",
        "# Ma'lumotlarni oldindan qayta ishlash\n",
        "df_train = preprocess_data(df_train)\n",
        "df_test = preprocess_data(df_test)\n",
        "\n",
        "# Ajratish\n",
        "X = df_train.drop('price', axis=1)\n",
        "Y = df_train['price'].copy()\n",
        "\n",
        "# Xususiyatlarni scalelash\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train model\n",
        "forest_model = RandomForestRegressor(n_estimators=1000)\n",
        "forest_model.fit(X_scaled, Y)\n",
        "\n",
        "# Test datani tayyorlash\n",
        "Test_scaled = scaler.transform(df_test)\n",
        "\n",
        "# Bashorat qilish\n",
        "test_predictions = forest_model.predict(Test_scaled)\n",
        "\n",
        "# Prediction ni CSV fayliga saqlash\n",
        "submission = pd.DataFrame(df_test['id'])\n",
        "submission['price'] = test_predictions\n",
        "submission.to_csv('/content/submission.csv', index=False)"
      ],
      "metadata": {
        "id": "p8vLPa1mPl1C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vx7Y7rc8QQnw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}